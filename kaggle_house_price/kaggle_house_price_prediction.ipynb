{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df['source'] = 'train'\n",
    "#df = df.drop(['Id'], axis = 1)\n",
    "df_test =pd.read_csv('test.csv')\n",
    "df_test['SalePrice'] = -1\n",
    "df_test['source'] = 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimColumns = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'GarageType', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition'  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimColumns.append('Neighborhood')\n",
    "dimColumns.append('Functional')\n",
    "dimColumns.append('FireplaceQu')\n",
    "dimColumns.append('GarageFinish')\n",
    "dimColumns.append('GarageQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in dimColumns:\n",
    "    dummies = pd.get_dummies(df[[c]])\n",
    "    df = pd.concat([df.drop([c], axis = 1), dummies], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = src_df[src_df['source'] == 'train']\n",
    "df = df.drop(['Id','source'], axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (12,8))\n",
    "# test = df[['SaleType', 'SalePrice']]\n",
    "# sns.scatterplot(df['SaleType'], df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage         70.049958\n",
       "LotArea          10382.000000\n",
       "MasVnrArea         240.000000\n",
       "BsmtFinSF1         859.000000\n",
       "BsmtFinSF2          32.000000\n",
       "                     ...     \n",
       "GarageQual_Ex        0.000000\n",
       "GarageQual_Fa        0.000000\n",
       "GarageQual_Gd        0.000000\n",
       "GarageQual_Po        0.000000\n",
       "GarageQual_TA        1.000000\n",
       "Name: 7, Length: 289, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('SalePrice', axis = 1)\n",
    "y = df['SalePrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978, 288)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(288, activation='selu'))\n",
    "# model.add(Dense(288, activation='selu'))\n",
    "# model.add(Dense(288, activation='selu'))\n",
    "# #model.add(Dense(288, activation='relu'))\n",
    "# #model.add(Dense(288, activation='relu'))\n",
    "# #model.add(Dense(256, activation='relu'))\n",
    "# #model.add(Dense(128, activation='relu'))\n",
    "# #model.add(Dense(64, activation='relu'))\n",
    "# #model.add(Dense(32, activation='relu'))\n",
    "# #model.add(Dense(16, activation='relu'))\n",
    "# #model.add(Dense(8, activation='relu'))\n",
    "# model.add(Dense(4, activation='selu'))\n",
    "# model.add(Dense(2, activation='selu'))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# model.compile(loss = 'mse', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(288, activation='relu'))\n",
    "model.add(Dense(288, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(288, activation='relu'))\n",
    "# model.add(Dense(288, activation='relu'))\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(16, activation='relu'))\n",
    "#model.add(Dense(8, activation='relu'))\n",
    "#model.add(Dense(4, activation='relu'))\n",
    "#model.add(Dense(2, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss = 'mse', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 978 samples, validate on 482 samples\n",
      "Epoch 1/700\n",
      "978/978 [==============================] - 2s 2ms/sample - loss: 38573746774.9039 - val_loss: 39977525978.8216\n",
      "Epoch 2/700\n",
      "978/978 [==============================] - 0s 254us/sample - loss: 38563754608.0327 - val_loss: 39953564225.8589\n",
      "Epoch 3/700\n",
      "978/978 [==============================] - 0s 259us/sample - loss: 38517268207.7710 - val_loss: 39861898533.1784\n",
      "Epoch 4/700\n",
      "978/978 [==============================] - 0s 285us/sample - loss: 38364805149.3170 - val_loss: 39597116930.1245\n",
      "Epoch 5/700\n",
      "978/978 [==============================] - 0s 289us/sample - loss: 37962663797.7914 - val_loss: 38962917308.0166\n",
      "Epoch 6/700\n",
      "978/978 [==============================] - 0s 291us/sample - loss: 37073242476.3681 - val_loss: 37641533091.5851\n",
      "Epoch 7/700\n",
      "978/978 [==============================] - 0s 301us/sample - loss: 35308309887.2147 - val_loss: 35193189133.8091\n",
      "Epoch 8/700\n",
      "978/978 [==============================] - 0s 277us/sample - loss: 32238256793.9141 - val_loss: 31128058476.3485\n",
      "Epoch 9/700\n",
      "978/978 [==============================] - 0s 331us/sample - loss: 27366813763.0102 - val_loss: 25149819024.4647\n",
      "Epoch 10/700\n",
      "978/978 [==============================] - 0s 323us/sample - loss: 20628855533.6769 - val_loss: 17615790012.0166\n",
      "Epoch 11/700\n",
      "978/978 [==============================] - 0s 333us/sample - loss: 12950246538.2086 - val_loss: 10273590403.7178\n",
      "Epoch 12/700\n",
      "978/978 [==============================] - 0s 306us/sample - loss: 6801614860.5644 - val_loss: 6243468984.8299\n",
      "Epoch 13/700\n",
      "978/978 [==============================] - 0s 432us/sample - loss: 4642993311.6728 - val_loss: 6104139255.5021\n",
      "Epoch 14/700\n",
      "978/978 [==============================] - 0s 356us/sample - loss: 4752082675.9591 - val_loss: 5827169577.4274\n",
      "Epoch 15/700\n",
      "978/978 [==============================] - 0s 333us/sample - loss: 4262228129.7669 - val_loss: 5265253320.7635\n",
      "Epoch 16/700\n",
      "978/978 [==============================] - 0s 351us/sample - loss: 3876423708.2699 - val_loss: 5059965820.2822\n",
      "Epoch 17/700\n",
      "978/978 [==============================] - 0s 361us/sample - loss: 3696109762.7485 - val_loss: 4840874411.0207\n",
      "Epoch 18/700\n",
      "978/978 [==============================] - 0s 369us/sample - loss: 3486015911.5256 - val_loss: 4607840336.7303\n",
      "Epoch 19/700\n",
      "978/978 [==============================] - 0s 432us/sample - loss: 3301945351.3292 - val_loss: 4412742560.3983\n",
      "Epoch 20/700\n",
      "978/978 [==============================] - 0s 396us/sample - loss: 3148803408.0982 - val_loss: 4235966306.7884\n",
      "Epoch 21/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 2996734956.6299 - val_loss: 4067883645.3444\n",
      "Epoch 22/700\n",
      "978/978 [==============================] - 0s 394us/sample - loss: 2862800927.9346 - val_loss: 3915409019.2199\n",
      "Epoch 23/700\n",
      "978/978 [==============================] - 0s 393us/sample - loss: 2730391273.4888 - val_loss: 3766777086.9378\n",
      "Epoch 24/700\n",
      "978/978 [==============================] - 0s 385us/sample - loss: 2611498166.1840 - val_loss: 3627641577.6929\n",
      "Epoch 25/700\n",
      "978/978 [==============================] - 0s 370us/sample - loss: 2502761377.2434 - val_loss: 3496231940.2490\n",
      "Epoch 26/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 2398191901.0552 - val_loss: 3374369207.7676\n",
      "Epoch 27/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 2300351917.5460 - val_loss: 3263018130.5892\n",
      "Epoch 28/700\n",
      "978/978 [==============================] - 0s 373us/sample - loss: 2213339108.7771 - val_loss: 3153046691.5851\n",
      "Epoch 29/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 2128474324.8098 - val_loss: 3052381264.7303\n",
      "Epoch 30/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 2057962331.6155 - val_loss: 2954072675.8506\n",
      "Epoch 31/700\n",
      "978/978 [==============================] - 0s 340us/sample - loss: 1986240272.2290 - val_loss: 2879030446.2075\n",
      "Epoch 32/700\n",
      "978/978 [==============================] - 0s 381us/sample - loss: 1916979093.7260 - val_loss: 2789835757.9419\n",
      "Epoch 33/700\n",
      "978/978 [==============================] - 0s 378us/sample - loss: 1858000769.5706 - val_loss: 2707096607.8672\n",
      "Epoch 34/700\n",
      "978/978 [==============================] - 0s 391us/sample - loss: 1798189214.7566 - val_loss: 2637121169.5270\n",
      "Epoch 35/700\n",
      "978/978 [==============================] - 0s 389us/sample - loss: 1744741317.3661 - val_loss: 2577227131.2199\n",
      "Epoch 36/700\n",
      "978/978 [==============================] - 0s 354us/sample - loss: 1695231492.7117 - val_loss: 2508041325.4108\n",
      "Epoch 37/700\n",
      "978/978 [==============================] - 0s 408us/sample - loss: 1649482116.7117 - val_loss: 2443268339.2531\n",
      "Epoch 38/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 1606572509.9714 - val_loss: 2385956276.5809\n",
      "Epoch 39/700\n",
      "978/978 [==============================] - 0s 392us/sample - loss: 1561404050.5849 - val_loss: 2342857001.4274\n",
      "Epoch 40/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 1523998974.1677 - val_loss: 2292123786.0913\n",
      "Epoch 41/700\n",
      "978/978 [==============================] - 0s 408us/sample - loss: 1487736345.1288 - val_loss: 2241197651.9170\n",
      "Epoch 42/700\n",
      "978/978 [==============================] - 0s 381us/sample - loss: 1451474307.0102 - val_loss: 2197151560.2324\n",
      "Epoch 43/700\n",
      "978/978 [==============================] - 0s 401us/sample - loss: 1418636510.4949 - val_loss: 2153770294.1743\n",
      "Epoch 44/700\n",
      "978/978 [==============================] - 0s 378us/sample - loss: 1383728177.7342 - val_loss: 2117670698.4896\n",
      "Epoch 45/700\n",
      "978/978 [==============================] - 0s 378us/sample - loss: 1354974863.1820 - val_loss: 2084522663.8340\n",
      "Epoch 46/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 1325250686.4294 - val_loss: 2038798840.5643\n",
      "Epoch 47/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 1298725551.9018 - val_loss: 2005400502.7054\n",
      "Epoch 48/700\n",
      "978/978 [==============================] - 0s 394us/sample - loss: 1271343332.3845 - val_loss: 1980442990.4730\n",
      "Epoch 49/700\n",
      "978/978 [==============================] - 0s 408us/sample - loss: 1242347520.3926 - val_loss: 1942802406.5062\n",
      "Epoch 50/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 1216842382.9202 - val_loss: 1912884090.1577\n",
      "Epoch 51/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 1194935318.7730 - val_loss: 1879125228.8797\n",
      "Epoch 52/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 1172882434.2249 - val_loss: 1851563937.4606\n",
      "Epoch 53/700\n",
      "978/978 [==============================] - 0s 403us/sample - loss: 1151172852.6135 - val_loss: 1827053165.4108\n",
      "Epoch 54/700\n",
      "978/978 [==============================] - 0s 382us/sample - loss: 1130793320.9652 - val_loss: 1806254870.3071\n",
      "Epoch 55/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 1109182571.8446 - val_loss: 1775001540.5145\n",
      "Epoch 56/700\n",
      "978/978 [==============================] - 0s 447us/sample - loss: 1094340330.0123 - val_loss: 1749166046.0083\n",
      "Epoch 57/700\n",
      "978/978 [==============================] - 0s 403us/sample - loss: 1073814917.2352 - val_loss: 1734747122.1909\n",
      "Epoch 58/700\n",
      "978/978 [==============================] - 0s 397us/sample - loss: 1059431686.2822 - val_loss: 1716245057.8589\n",
      "Epoch 59/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 1049020374.9693 - val_loss: 1683310778.9544\n",
      "Epoch 60/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 1031874890.6012 - val_loss: 1678923125.9087\n",
      "Epoch 61/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 1017236678.4131 - val_loss: 1654588123.8838\n",
      "Epoch 62/700\n",
      "978/978 [==============================] - 0s 445us/sample - loss: 999522229.6605 - val_loss: 1643360244.3154\n",
      "Epoch 63/700\n",
      "978/978 [==============================] - 0s 412us/sample - loss: 990967502.3967 - val_loss: 1629950386.4564\n",
      "Epoch 64/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 975023474.3885 - val_loss: 1606868589.4108\n",
      "Epoch 65/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 964321785.1943 - val_loss: 1595959003.8838\n",
      "Epoch 66/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978/978 [==============================] - 0s 389us/sample - loss: 952388096.7853 - val_loss: 1585732175.6680\n",
      "Epoch 67/700\n",
      "978/978 [==============================] - 0s 410us/sample - loss: 948619189.6605 - val_loss: 1579838321.6598\n",
      "Epoch 68/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 935654195.5665 - val_loss: 1556283734.0415\n",
      "Epoch 69/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 925127013.6933 - val_loss: 1551878456.2988\n",
      "Epoch 70/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 916080504.9325 - val_loss: 1537451688.8963\n",
      "Epoch 71/700\n",
      "978/978 [==============================] - 0s 382us/sample - loss: 904351456.3272 - val_loss: 1532732508.4149\n",
      "Epoch 72/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 895705150.5603 - val_loss: 1519323242.2241\n",
      "Epoch 73/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 887239720.9652 - val_loss: 1511872945.3942\n",
      "Epoch 74/700\n",
      "978/978 [==============================] - 0s 382us/sample - loss: 879782837.6605 - val_loss: 1501883297.4606\n",
      "Epoch 75/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 870674315.7791 - val_loss: 1492032446.1411\n",
      "Epoch 76/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 864053421.1534 - val_loss: 1479736826.6888\n",
      "Epoch 77/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 856367229.7751 - val_loss: 1473277014.0415\n",
      "Epoch 78/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 851156981.3988 - val_loss: 1460697027.4523\n",
      "Epoch 79/700\n",
      "978/978 [==============================] - 0s 387us/sample - loss: 843097765.4315 - val_loss: 1460014124.6141\n",
      "Epoch 80/700\n",
      "978/978 [==============================] - 0s 429us/sample - loss: 837533411.2065 - val_loss: 1447761080.8299\n",
      "Epoch 81/700\n",
      "978/978 [==============================] - 0s 406us/sample - loss: 833604951.4274 - val_loss: 1438031271.8340\n",
      "Epoch 82/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 826322091.5828 - val_loss: 1444008131.4523\n",
      "Epoch 83/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 820630064.6871 - val_loss: 1427897293.0124\n",
      "Epoch 84/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 814920217.1288 - val_loss: 1421226418.4564\n",
      "Epoch 85/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 806281803.7791 - val_loss: 1434109575.9668\n",
      "Epoch 86/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 802570946.6830 - val_loss: 1408717883.4855\n",
      "Epoch 87/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 796860488.6380 - val_loss: 1408053273.4938\n",
      "Epoch 88/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 789962332.9243 - val_loss: 1402065889.1950\n",
      "Epoch 89/700\n",
      "978/978 [==============================] - 0s 437us/sample - loss: 782881733.1043 - val_loss: 1393112097.9917\n",
      "Epoch 90/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 777269374.0368 - val_loss: 1391755097.2282\n",
      "Epoch 91/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 773748859.0920 - val_loss: 1389043702.4398\n",
      "Epoch 92/700\n",
      "978/978 [==============================] - 0s 391us/sample - loss: 770038193.4724 - val_loss: 1378452645.7095\n",
      "Epoch 93/700\n",
      "978/978 [==============================] - 0s 368us/sample - loss: 763520452.4499 - val_loss: 1375772192.9295\n",
      "Epoch 94/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 758251371.8446 - val_loss: 1374238666.8880\n",
      "Epoch 95/700\n",
      "978/978 [==============================] - 0s 402us/sample - loss: 753599818.8630 - val_loss: 1365137088.2656\n",
      "Epoch 96/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 747677488.0327 - val_loss: 1365464759.7676\n",
      "Epoch 97/700\n",
      "978/978 [==============================] - 0s 445us/sample - loss: 744313796.0573 - val_loss: 1362032096.1328\n",
      "Epoch 98/700\n",
      "978/978 [==============================] - 0s 449us/sample - loss: 739653027.8609 - val_loss: 1353533894.6390\n",
      "Epoch 99/700\n",
      "978/978 [==============================] - 0s 395us/sample - loss: 734965791.2802 - val_loss: 1354799612.8133\n",
      "Epoch 100/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 733578620.2045 - val_loss: 1349938951.4357\n",
      "Epoch 101/700\n",
      "978/978 [==============================] - 0s 450us/sample - loss: 727766436.1227 - val_loss: 1343048716.7469\n",
      "Epoch 102/700\n",
      "978/978 [==============================] - 0s 398us/sample - loss: 724622970.7648 - val_loss: 1341076969.6929\n",
      "Epoch 103/700\n",
      "978/978 [==============================] - 0s 410us/sample - loss: 720614871.6892 - val_loss: 1344170872.0332\n",
      "Epoch 104/700\n",
      "978/978 [==============================] - 0s 396us/sample - loss: 722035433.7505 - val_loss: 1332228272.3320\n",
      "Epoch 105/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 710883822.2004 - val_loss: 1334146185.0290\n",
      "Epoch 106/700\n",
      "978/978 [==============================] - 0s 471us/sample - loss: 707032446.1677 - val_loss: 1330552457.0290\n",
      "Epoch 107/700\n",
      "978/978 [==============================] - 0s 429us/sample - loss: 704479556.1881 - val_loss: 1330591024.8631\n",
      "Epoch 108/700\n",
      "978/978 [==============================] - 0s 449us/sample - loss: 700026534.4785 - val_loss: 1325448184.5643\n",
      "Epoch 109/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 701954659.1411 - val_loss: 1317765435.4855\n",
      "Epoch 110/700\n",
      "978/978 [==============================] - 0s 448us/sample - loss: 690180197.3006 - val_loss: 1320554162.4564\n",
      "Epoch 111/700\n",
      "978/978 [==============================] - 0s 429us/sample - loss: 690852640.1963 - val_loss: 1314799390.8050\n",
      "Epoch 112/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 687208453.7587 - val_loss: 1307447314.0581\n",
      "Epoch 113/700\n",
      "978/978 [==============================] - 0s 406us/sample - loss: 683120122.3722 - val_loss: 1312768261.3112\n",
      "Epoch 114/700\n",
      "978/978 [==============================] - 0s 459us/sample - loss: 684079334.8712 - val_loss: 1304243705.6266\n",
      "Epoch 115/700\n",
      "978/978 [==============================] - 0s 423us/sample - loss: 678407794.4540 - val_loss: 1311194000.4647\n",
      "Epoch 116/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 674374301.4479 - val_loss: 1300775229.6100\n",
      "Epoch 117/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 670289491.5010 - val_loss: 1300729549.0124\n",
      "Epoch 118/700\n",
      "978/978 [==============================] - 0s 454us/sample - loss: 669413107.8282 - val_loss: 1298547513.3610\n",
      "Epoch 119/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 669760340.8098 - val_loss: 1293085199.9336\n",
      "Epoch 120/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 671709650.3231 - val_loss: 1302596067.3195\n",
      "Epoch 121/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 664512835.1411 - val_loss: 1286841408.7967\n",
      "Epoch 122/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 659986531.0757 - val_loss: 1292412231.1701\n",
      "Epoch 123/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 653017985.0470 - val_loss: 1282211440.5975\n",
      "Epoch 124/700\n",
      "978/978 [==============================] - 0s 423us/sample - loss: 649973274.0450 - val_loss: 1278607213.4108\n",
      "Epoch 125/700\n",
      "978/978 [==============================] - 0s 388us/sample - loss: 647090311.0675 - val_loss: 1277925876.3154\n",
      "Epoch 126/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 644345206.3149 - val_loss: 1276042685.0788\n",
      "Epoch 127/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 641758703.6401 - val_loss: 1272858612.3154\n",
      "Epoch 128/700\n",
      "978/978 [==============================] - 0s 433us/sample - loss: 640011514.3722 - val_loss: 1273469630.1411\n",
      "Epoch 129/700\n",
      "978/978 [==============================] - 0s 410us/sample - loss: 638358031.8364 - val_loss: 1271071772.6805\n",
      "Epoch 130/700\n",
      "978/978 [==============================] - 0s 450us/sample - loss: 633298420.7444 - val_loss: 1267509072.7303\n",
      "Epoch 131/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 631838890.5358 - val_loss: 1263506126.0747\n",
      "Epoch 132/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978/978 [==============================] - 0s 385us/sample - loss: 633218139.2883 - val_loss: 1266274022.5062\n",
      "Epoch 133/700\n",
      "978/978 [==============================] - 0s 438us/sample - loss: 627714889.8160 - val_loss: 1263308056.4315\n",
      "Epoch 134/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 625583695.9673 - val_loss: 1263924969.6929\n",
      "Epoch 135/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 624665745.1452 - val_loss: 1254933540.1162\n",
      "Epoch 136/700\n",
      "978/978 [==============================] - 0s 382us/sample - loss: 621852685.4806 - val_loss: 1257345221.5768\n",
      "Epoch 137/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 615873700.8425 - val_loss: 1252330535.3029\n",
      "Epoch 138/700\n",
      "978/978 [==============================] - 0s 399us/sample - loss: 615271815.0675 - val_loss: 1249586423.5021\n",
      "Epoch 139/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 616970664.1145 - val_loss: 1254287005.2116\n",
      "Epoch 140/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 608937761.7014 - val_loss: 1247251612.6805\n",
      "Epoch 141/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 608235641.6524 - val_loss: 1247621004.2158\n",
      "Epoch 142/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 607089671.8528 - val_loss: 1244244582.5062\n",
      "Epoch 143/700\n",
      "978/978 [==============================] - 0s 454us/sample - loss: 603065369.9796 - val_loss: 1240531536.7303\n",
      "Epoch 144/700\n",
      "978/978 [==============================] - 0s 433us/sample - loss: 600311488.0000 - val_loss: 1243572422.1079\n",
      "Epoch 145/700\n",
      "978/978 [==============================] - 0s 432us/sample - loss: 598634210.7485 - val_loss: 1238341220.9129\n",
      "Epoch 146/700\n",
      "978/978 [==============================] - 0s 410us/sample - loss: 597598190.9202 - val_loss: 1235171613.7427\n",
      "Epoch 147/700\n",
      "978/978 [==============================] - 0s 405us/sample - loss: 595979634.1922 - val_loss: 1239093428.5809\n",
      "Epoch 148/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 591837833.1616 - val_loss: 1232686836.8465\n",
      "Epoch 149/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 589742952.9652 - val_loss: 1231162157.6763\n",
      "Epoch 150/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 589053575.3947 - val_loss: 1232146524.9461\n",
      "Epoch 151/700\n",
      "978/978 [==============================] - 0s 383us/sample - loss: 585304292.1227 - val_loss: 1228403923.9170\n",
      "Epoch 152/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 585942569.4888 - val_loss: 1224822548.1826\n",
      "Epoch 153/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 582035917.8078 - val_loss: 1223197357.1452\n",
      "Epoch 154/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 583711462.1513 - val_loss: 1224211654.6390\n",
      "Epoch 155/700\n",
      "978/978 [==============================] - 0s 457us/sample - loss: 577952072.8998 - val_loss: 1221781848.6971\n",
      "Epoch 156/700\n",
      "978/978 [==============================] - 0s 419us/sample - loss: 576954689.5706 - val_loss: 1221102617.4938\n",
      "Epoch 157/700\n",
      "978/978 [==============================] - 0s 446us/sample - loss: 573865079.2638 - val_loss: 1218408007.7012\n",
      "Epoch 158/700\n",
      "978/978 [==============================] - 0s 394us/sample - loss: 580068829.1207 - val_loss: 1214162260.9793\n",
      "Epoch 159/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 571623093.9877 - val_loss: 1221025600.2656\n",
      "Epoch 160/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 569609841.4070 - val_loss: 1215090713.4938\n",
      "Epoch 161/700\n",
      "978/978 [==============================] - 0s 423us/sample - loss: 575433781.3988 - val_loss: 1212585078.4398\n",
      "Epoch 162/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 570254088.5072 - val_loss: 1219640452.7801\n",
      "Epoch 163/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 562055172.6462 - val_loss: 1214245557.6432\n",
      "Epoch 164/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 564389179.3538 - val_loss: 1212092137.6929\n",
      "Epoch 165/700\n",
      "978/978 [==============================] - 0s 399us/sample - loss: 559637514.0123 - val_loss: 1209385841.1286\n",
      "Epoch 166/700\n",
      "978/978 [==============================] - 0s 449us/sample - loss: 558818361.6524 - val_loss: 1206245665.4606\n",
      "Epoch 167/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 555441872.4908 - val_loss: 1208396750.6058\n",
      "Epoch 168/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 555809345.4397 - val_loss: 1205500177.5270\n",
      "Epoch 169/700\n",
      "978/978 [==============================] - 0s 382us/sample - loss: 560119071.8037 - val_loss: 1202331943.3029\n",
      "Epoch 170/700\n",
      "978/978 [==============================] - 0s 455us/sample - loss: 552585022.3640 - val_loss: 1207498596.3817\n",
      "Epoch 171/700\n",
      "978/978 [==============================] - 0s 455us/sample - loss: 548582450.2577 - val_loss: 1203848479.8672\n",
      "Epoch 172/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 554750256.8834 - val_loss: 1201345015.5021\n",
      "Epoch 173/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 549731571.0429 - val_loss: 1199611384.5643\n",
      "Epoch 174/700\n",
      "978/978 [==============================] - 0s 448us/sample - loss: 543355772.0082 - val_loss: 1200140703.3361\n",
      "Epoch 175/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 545317090.9448 - val_loss: 1200985438.0083\n",
      "Epoch 176/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 542606474.8630 - val_loss: 1196307282.3237\n",
      "Epoch 177/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 540244567.9509 - val_loss: 1196892068.6473\n",
      "Epoch 178/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 539245689.3906 - val_loss: 1195252563.9170\n",
      "Epoch 179/700\n",
      "978/978 [==============================] - 0s 448us/sample - loss: 538731748.4499 - val_loss: 1190025973.9087\n",
      "Epoch 180/700\n",
      "978/978 [==============================] - 0s 452us/sample - loss: 534294460.9898 - val_loss: 1188324250.0249\n",
      "Epoch 181/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 536171256.2127 - val_loss: 1185625746.5892\n",
      "Epoch 182/700\n",
      "978/978 [==============================] - 0s 399us/sample - loss: 533980691.8937 - val_loss: 1187075279.1369\n",
      "Epoch 183/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 528555255.1656 - val_loss: 1185510391.5021\n",
      "Epoch 184/700\n",
      "978/978 [==============================] - 0s 458us/sample - loss: 528983544.9325 - val_loss: 1186299892.3154\n",
      "Epoch 185/700\n",
      "978/978 [==============================] - 0s 454us/sample - loss: 526728044.4335 - val_loss: 1186031550.6722\n",
      "Epoch 186/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 528706479.3129 - val_loss: 1183376094.0083\n",
      "Epoch 187/700\n",
      "978/978 [==============================] - 0s 404us/sample - loss: 527685535.0838 - val_loss: 1188123397.3112\n",
      "Epoch 188/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 520763636.1554 - val_loss: 1185352810.7552\n",
      "Epoch 189/700\n",
      "978/978 [==============================] - 0s 405us/sample - loss: 522701687.0348 - val_loss: 1185696301.1452\n",
      "Epoch 190/700\n",
      "978/978 [==============================] - 0s 371us/sample - loss: 517438952.7035 - val_loss: 1180183703.9004\n",
      "Epoch 191/700\n",
      "978/978 [==============================] - 0s 446us/sample - loss: 522824010.4049 - val_loss: 1177861462.0415\n",
      "Epoch 192/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 517999984.2945 - val_loss: 1176173481.4274\n",
      "Epoch 193/700\n",
      "978/978 [==============================] - 0s 428us/sample - loss: 515421811.6319 - val_loss: 1175839139.0539\n",
      "Epoch 194/700\n",
      "978/978 [==============================] - 0s 437us/sample - loss: 513332786.0613 - val_loss: 1174508583.3029\n",
      "Epoch 195/700\n",
      "978/978 [==============================] - 0s 388us/sample - loss: 510660920.9325 - val_loss: 1173555684.3817\n",
      "Epoch 196/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 509775231.7382 - val_loss: 1171875435.8174\n",
      "Epoch 197/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 508449755.2229 - val_loss: 1171784706.6556\n",
      "Epoch 198/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978/978 [==============================] - 0s 452us/sample - loss: 508797455.8364 - val_loss: 1170900290.9212\n",
      "Epoch 199/700\n",
      "978/978 [==============================] - 0s 410us/sample - loss: 512314457.9141 - val_loss: 1168699972.5145\n",
      "Epoch 200/700\n",
      "978/978 [==============================] - 0s 428us/sample - loss: 503981716.4172 - val_loss: 1170348181.2448\n",
      "Epoch 201/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 502925328.3599 - val_loss: 1167706339.3195\n",
      "Epoch 202/700\n",
      "978/978 [==============================] - 0s 449us/sample - loss: 502374182.6748 - val_loss: 1165289880.4315\n",
      "Epoch 203/700\n",
      "978/978 [==============================] - 0s 429us/sample - loss: 500515250.3885 - val_loss: 1167486470.9046\n",
      "Epoch 204/700\n",
      "978/978 [==============================] - 0s 447us/sample - loss: 502405869.0879 - val_loss: 1164699851.4191\n",
      "Epoch 205/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 498289484.1063 - val_loss: 1164354154.2241\n",
      "Epoch 206/700\n",
      "978/978 [==============================] - 0s 457us/sample - loss: 497691872.9162 - val_loss: 1162110769.3942\n",
      "Epoch 207/700\n",
      "978/978 [==============================] - 0s 428us/sample - loss: 501457007.7710 - val_loss: 1164209161.0290\n",
      "Epoch 208/700\n",
      "978/978 [==============================] - 0s 403us/sample - loss: 491371851.3211 - val_loss: 1162248706.1245\n",
      "Epoch 209/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 493740070.1513 - val_loss: 1163638955.5519\n",
      "Epoch 210/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 492852379.8773 - val_loss: 1157258775.9004\n",
      "Epoch 211/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 487009408.7853 - val_loss: 1155998588.8133\n",
      "Epoch 212/700\n",
      "978/978 [==============================] - 0s 446us/sample - loss: 488352290.0286 - val_loss: 1155951718.5062\n",
      "Epoch 213/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 483982022.9366 - val_loss: 1155231478.4398\n",
      "Epoch 214/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 484570747.6810 - val_loss: 1155910755.8506\n",
      "Epoch 215/700\n",
      "978/978 [==============================] - 0s 460us/sample - loss: 481271100.7280 - val_loss: 1152765015.6349\n",
      "Epoch 216/700\n",
      "978/978 [==============================] - 0s 428us/sample - loss: 480283808.4581 - val_loss: 1153522985.9585\n",
      "Epoch 217/700\n",
      "978/978 [==============================] - 0s 402us/sample - loss: 481878439.7873 - val_loss: 1152609853.0788\n",
      "Epoch 218/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 482239128.8671 - val_loss: 1150606503.3029\n",
      "Epoch 219/700\n",
      "978/978 [==============================] - 0s 423us/sample - loss: 478459549.5133 - val_loss: 1152941274.2905\n",
      "Epoch 220/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 479378066.7812 - val_loss: 1146246170.5560\n",
      "Epoch 221/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 477780728.1472 - val_loss: 1149556678.1079\n",
      "Epoch 222/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 470111406.7239 - val_loss: 1144546014.0083\n",
      "Epoch 223/700\n",
      "978/978 [==============================] - 0s 451us/sample - loss: 471848625.4070 - val_loss: 1143924994.1245\n",
      "Epoch 224/700\n",
      "978/978 [==============================] - 0s 391us/sample - loss: 476361006.7894 - val_loss: 1142842695.1701\n",
      "Epoch 225/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 471996751.2147 - val_loss: 1141652898.5228\n",
      "Epoch 226/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 476114803.5665 - val_loss: 1140923884.8797\n",
      "Epoch 227/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 465474084.9080 - val_loss: 1141997432.5643\n",
      "Epoch 228/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 462293180.7607 - val_loss: 1142976456.7635\n",
      "Epoch 229/700\n",
      "978/978 [==============================] - 0s 452us/sample - loss: 464521590.3804 - val_loss: 1141387742.5394\n",
      "Epoch 230/700\n",
      "978/978 [==============================] - 0s 448us/sample - loss: 468852632.4744 - val_loss: 1138809998.3402\n",
      "Epoch 231/700\n",
      "978/978 [==============================] - 0s 445us/sample - loss: 461211143.4601 - val_loss: 1134499401.8257\n",
      "Epoch 232/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 459176374.6421 - val_loss: 1134473560.6971\n",
      "Epoch 233/700\n",
      "978/978 [==============================] - 0s 396us/sample - loss: 456841590.4458 - val_loss: 1133923484.1494\n",
      "Epoch 234/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 457345059.1084 - val_loss: 1132140078.7386\n",
      "Epoch 235/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 453837978.1104 - val_loss: 1133682479.8008\n",
      "Epoch 236/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 453089079.6237 - val_loss: 1131777315.5851\n",
      "Epoch 237/700\n",
      "978/978 [==============================] - 0s 412us/sample - loss: 449410168.2781 - val_loss: 1132974488.4315\n",
      "Epoch 238/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 450891246.1350 - val_loss: 1130835549.4772\n",
      "Epoch 239/700\n",
      "978/978 [==============================] - 0s 432us/sample - loss: 451192622.7239 - val_loss: 1128148254.8050\n",
      "Epoch 240/700\n",
      "978/978 [==============================] - 0s 392us/sample - loss: 448661548.3681 - val_loss: 1125974008.5643\n",
      "Epoch 241/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 446082847.9346 - val_loss: 1125386894.3402\n",
      "Epoch 242/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 446231641.5869 - val_loss: 1127190846.6722\n",
      "Epoch 243/700\n",
      "978/978 [==============================] - 0s 401us/sample - loss: 442214304.7853 - val_loss: 1125838457.0954\n",
      "Epoch 244/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 442234696.9652 - val_loss: 1123524475.2199\n",
      "Epoch 245/700\n",
      "978/978 [==============================] - 0s 454us/sample - loss: 439042080.3272 - val_loss: 1121660820.1826\n",
      "Epoch 246/700\n",
      "978/978 [==============================] - 0s 397us/sample - loss: 437642746.1431 - val_loss: 1119168897.0622\n",
      "Epoch 247/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 437646322.1268 - val_loss: 1117481375.8672\n",
      "Epoch 248/700\n",
      "978/978 [==============================] - 0s 406us/sample - loss: 436048069.6933 - val_loss: 1120244759.3693\n",
      "Epoch 249/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 432945790.1022 - val_loss: 1119793213.0788\n",
      "Epoch 250/700\n",
      "978/978 [==============================] - 0s 388us/sample - loss: 436470442.5358 - val_loss: 1120400519.4357\n",
      "Epoch 251/700\n",
      "978/978 [==============================] - 0s 437us/sample - loss: 431838969.5869 - val_loss: 1115413501.3444\n",
      "Epoch 252/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 430800158.8875 - val_loss: 1113505307.0871\n",
      "Epoch 253/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 431944643.2720 - val_loss: 1114213374.9378\n",
      "Epoch 254/700\n",
      "978/978 [==============================] - 0s 401us/sample - loss: 428512810.9284 - val_loss: 1111667897.8921\n",
      "Epoch 255/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 425622926.7239 - val_loss: 1112920311.5021\n",
      "Epoch 256/700\n",
      "978/978 [==============================] - 0s 408us/sample - loss: 425197176.8998 - val_loss: 1111326176.6639\n",
      "Epoch 257/700\n",
      "978/978 [==============================] - 0s 412us/sample - loss: 425458153.7505 - val_loss: 1111544764.5477\n",
      "Epoch 258/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 423710636.3681 - val_loss: 1112765408.6639\n",
      "Epoch 259/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 426168010.7975 - val_loss: 1109207636.4481\n",
      "Epoch 260/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 428676367.3129 - val_loss: 1103798808.4315\n",
      "Epoch 261/700\n",
      "978/978 [==============================] - 0s 419us/sample - loss: 422220605.9059 - val_loss: 1105108905.9585\n",
      "Epoch 262/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 420140779.6483 - val_loss: 1106239750.3734\n",
      "Epoch 263/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 419908053.1697 - val_loss: 1102312699.2199\n",
      "Epoch 264/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978/978 [==============================] - 0s 409us/sample - loss: 420403677.7423 - val_loss: 1098776074.0913\n",
      "Epoch 265/700\n",
      "978/978 [==============================] - 0s 405us/sample - loss: 415901344.6544 - val_loss: 1100444256.1328\n",
      "Epoch 266/700\n",
      "978/978 [==============================] - 0s 419us/sample - loss: 412933578.4049 - val_loss: 1097584952.8299\n",
      "Epoch 267/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 411005413.5624 - val_loss: 1098938468.3817\n",
      "Epoch 268/700\n",
      "978/978 [==============================] - 0s 443us/sample - loss: 412967988.2209 - val_loss: 1099703063.9004\n",
      "Epoch 269/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 407913441.2434 - val_loss: 1095890530.7884\n",
      "Epoch 270/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 407310702.3313 - val_loss: 1097813665.9917\n",
      "Epoch 271/700\n",
      "978/978 [==============================] - 0s 412us/sample - loss: 405800531.3047 - val_loss: 1093049051.8838\n",
      "Epoch 272/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 404558586.6339 - val_loss: 1091971941.9751\n",
      "Epoch 273/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 403744453.6933 - val_loss: 1093063562.0913\n",
      "Epoch 274/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 405276230.6748 - val_loss: 1088797946.6888\n",
      "Epoch 275/700\n",
      "978/978 [==============================] - 0s 399us/sample - loss: 403962201.3906 - val_loss: 1088510782.1411\n",
      "Epoch 276/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 401234335.4110 - val_loss: 1091070623.3361\n",
      "Epoch 277/700\n",
      "978/978 [==============================] - 0s 447us/sample - loss: 398711112.5072 - val_loss: 1090694840.2988\n",
      "Epoch 278/700\n",
      "978/978 [==============================] - 0s 432us/sample - loss: 398888667.2883 - val_loss: 1086543778.5228\n",
      "Epoch 279/700\n",
      "978/978 [==============================] - 0s 433us/sample - loss: 395935207.6237 - val_loss: 1086270247.8340\n",
      "Epoch 280/700\n",
      "978/978 [==============================] - 0s 438us/sample - loss: 394050427.6155 - val_loss: 1087653619.7842\n",
      "Epoch 281/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 393155772.6299 - val_loss: 1086002090.4896\n",
      "Epoch 282/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 392316657.6033 - val_loss: 1088385491.9170\n",
      "Epoch 283/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 397447469.2843 - val_loss: 1081892525.6763\n",
      "Epoch 284/700\n",
      "978/978 [==============================] - 0s 423us/sample - loss: 396325675.9100 - val_loss: 1081837719.3693\n",
      "Epoch 285/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 391696051.8609 - val_loss: 1082325605.9751\n",
      "Epoch 286/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 387323694.4622 - val_loss: 1081662408.2324\n",
      "Epoch 287/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 385972258.8139 - val_loss: 1079492721.1286\n",
      "Epoch 288/700\n",
      "978/978 [==============================] - 0s 428us/sample - loss: 385379546.7648 - val_loss: 1078944757.9087\n",
      "Epoch 289/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 384917656.4744 - val_loss: 1078425628.6805\n",
      "Epoch 290/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 383693344.5890 - val_loss: 1077156195.3195\n",
      "Epoch 291/700\n",
      "978/978 [==============================] - 0s 423us/sample - loss: 381167701.5297 - val_loss: 1075516701.7427\n",
      "Epoch 292/700\n",
      "978/978 [==============================] - 0s 423us/sample - loss: 381057029.4969 - val_loss: 1077294618.5560\n",
      "Epoch 293/700\n",
      "978/978 [==============================] - 0s 437us/sample - loss: 381173933.9387 - val_loss: 1076419057.1286\n",
      "Epoch 294/700\n",
      "978/978 [==============================] - 0s 453us/sample - loss: 380535864.2781 - val_loss: 1073632325.5768\n",
      "Epoch 295/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 377752095.6728 - val_loss: 1071689137.3942\n",
      "Epoch 296/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 375762622.4294 - val_loss: 1071200793.4938\n",
      "Epoch 297/700\n",
      "978/978 [==============================] - 0s 447us/sample - loss: 377640651.7791 - val_loss: 1072194296.0332\n",
      "Epoch 298/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 375342461.7751 - val_loss: 1070094467.7178\n",
      "Epoch 299/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 375428979.4356 - val_loss: 1068611195.7510\n",
      "Epoch 300/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 370734696.5072 - val_loss: 1067832002.9212\n",
      "Epoch 301/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 369821515.3865 - val_loss: 1067774086.3734\n",
      "Epoch 302/700\n",
      "978/978 [==============================] - 0s 461us/sample - loss: 368406223.7710 - val_loss: 1066580121.4938\n",
      "Epoch 303/700\n",
      "978/978 [==============================] - 0s 450us/sample - loss: 369211618.0286 - val_loss: 1064531870.2739\n",
      "Epoch 304/700\n",
      "978/978 [==============================] - 0s 438us/sample - loss: 368171494.8057 - val_loss: 1065724655.5353\n",
      "Epoch 305/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 364294366.5603 - val_loss: 1067398230.5726\n",
      "Epoch 306/700\n",
      "978/978 [==============================] - 0s 408us/sample - loss: 363605757.8078 - val_loss: 1063554712.9627\n",
      "Epoch 307/700\n",
      "978/978 [==============================] - 0s 395us/sample - loss: 362577016.8671 - val_loss: 1062507240.0996\n",
      "Epoch 308/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 361723651.1411 - val_loss: 1060943237.8423\n",
      "Epoch 309/700\n",
      "978/978 [==============================] - 0s 466us/sample - loss: 364616964.1881 - val_loss: 1057902008.2988\n",
      "Epoch 310/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 366539459.4029 - val_loss: 1060079664.8631\n",
      "Epoch 311/700\n",
      "978/978 [==============================] - 0s 432us/sample - loss: 361485572.9734 - val_loss: 1060710268.2822\n",
      "Epoch 312/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 360300207.5092 - val_loss: 1057171219.6515\n",
      "Epoch 313/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 357478941.9059 - val_loss: 1055294420.9793\n",
      "Epoch 314/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 358527060.7444 - val_loss: 1056755835.7510\n",
      "Epoch 315/700\n",
      "978/978 [==============================] - 0s 429us/sample - loss: 360471632.4254 - val_loss: 1053348760.9627\n",
      "Epoch 316/700\n",
      "978/978 [==============================] - 0s 406us/sample - loss: 356162160.9162 - val_loss: 1049312312.8299\n",
      "Epoch 317/700\n",
      "978/978 [==============================] - 0s 432us/sample - loss: 351766502.4131 - val_loss: 1049238004.8465\n",
      "Epoch 318/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 351694940.5317 - val_loss: 1052506409.9585\n",
      "Epoch 319/700\n",
      "978/978 [==============================] - 0s 447us/sample - loss: 352073363.9591 - val_loss: 1049737470.4066\n",
      "Epoch 320/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 352815422.4949 - val_loss: 1048714230.4398\n",
      "Epoch 321/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 349281124.1881 - val_loss: 1048731173.7095\n",
      "Epoch 322/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 349283180.6299 - val_loss: 1042279857.3942\n",
      "Epoch 323/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 348773337.0634 - val_loss: 1044038333.0788\n",
      "Epoch 324/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 347425826.0613 - val_loss: 1044873889.4606\n",
      "Epoch 325/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 343494131.1738 - val_loss: 1046128519.9668\n",
      "Epoch 326/700\n",
      "978/978 [==============================] - 0s 449us/sample - loss: 343921487.0511 - val_loss: 1042185895.3029\n",
      "Epoch 327/700\n",
      "978/978 [==============================] - 0s 410us/sample - loss: 341910519.8200 - val_loss: 1040848159.8672\n",
      "Epoch 328/700\n",
      "978/978 [==============================] - 0s 438us/sample - loss: 341550808.2127 - val_loss: 1041266267.3527\n",
      "Epoch 329/700\n",
      "978/978 [==============================] - 0s 438us/sample - loss: 341501427.1084 - val_loss: 1041663501.2780\n",
      "Epoch 330/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978/978 [==============================] - 0s 422us/sample - loss: 337503604.4826 - val_loss: 1039347381.6432\n",
      "Epoch 331/700\n",
      "978/978 [==============================] - 0s 449us/sample - loss: 338341717.0716 - val_loss: 1044489675.9502\n",
      "Epoch 332/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 343582942.1677 - val_loss: 1042559634.5892\n",
      "Epoch 333/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 344747235.2065 - val_loss: 1050028230.1079\n",
      "Epoch 334/700\n",
      "978/978 [==============================] - 0s 429us/sample - loss: 340977583.7710 - val_loss: 1040236919.5021\n",
      "Epoch 335/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 339998676.5481 - val_loss: 1042605692.2822\n",
      "Epoch 336/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 338025663.5419 - val_loss: 1033961127.3029\n",
      "Epoch 337/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 330917302.2495 - val_loss: 1033737609.0290\n",
      "Epoch 338/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 330841614.3313 - val_loss: 1034054496.1328\n",
      "Epoch 339/700\n",
      "978/978 [==============================] - 0s 432us/sample - loss: 331871815.0020 - val_loss: 1033858205.7427\n",
      "Epoch 340/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 331430692.9734 - val_loss: 1035461003.6846\n",
      "Epoch 341/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 327134039.6237 - val_loss: 1028646961.3942\n",
      "Epoch 342/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 327286613.3988 - val_loss: 1027662175.6017\n",
      "Epoch 343/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 326112619.0593 - val_loss: 1028314807.7676\n",
      "Epoch 344/700\n",
      "978/978 [==============================] - 0s 438us/sample - loss: 327380769.6687 - val_loss: 1025787866.8216\n",
      "Epoch 345/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 322552707.0102 - val_loss: 1030073356.2158\n",
      "Epoch 346/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 321910147.0102 - val_loss: 1026469255.4357\n",
      "Epoch 347/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 320679857.4070 - val_loss: 1025509084.4149\n",
      "Epoch 348/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 319389098.8630 - val_loss: 1022256363.8174\n",
      "Epoch 349/700\n",
      "978/978 [==============================] - 0s 412us/sample - loss: 317758798.9202 - val_loss: 1021855148.6141\n",
      "Epoch 350/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 316369671.1984 - val_loss: 1019755978.8880\n",
      "Epoch 351/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 315230175.2802 - val_loss: 1018679966.8050\n",
      "Epoch 352/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 314729162.7975 - val_loss: 1018949603.3195\n",
      "Epoch 353/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 313766966.8712 - val_loss: 1015528627.5187\n",
      "Epoch 354/700\n",
      "978/978 [==============================] - 0s 445us/sample - loss: 311919184.4908 - val_loss: 1018905756.6805\n",
      "Epoch 355/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 311058152.6708 - val_loss: 1016994083.5851\n",
      "Epoch 356/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 311506142.3313 - val_loss: 1014876588.6141\n",
      "Epoch 357/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 309787219.9591 - val_loss: 1011952673.4606\n",
      "Epoch 358/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 309357475.0757 - val_loss: 1011800519.1701\n",
      "Epoch 359/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 310060058.6994 - val_loss: 1012814446.4730\n",
      "Epoch 360/700\n",
      "978/978 [==============================] - 0s 405us/sample - loss: 312244724.0245 - val_loss: 1011122119.7012\n",
      "Epoch 361/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 312077225.8814 - val_loss: 1011034200.6971\n",
      "Epoch 362/700\n",
      "978/978 [==============================] - 0s 437us/sample - loss: 303840732.1391 - val_loss: 1008791460.1162\n",
      "Epoch 363/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 303110544.6544 - val_loss: 1009400492.6141\n",
      "Epoch 364/700\n",
      "978/978 [==============================] - 0s 438us/sample - loss: 301932372.1881 - val_loss: 1006074920.3651\n",
      "Epoch 365/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 302095173.4315 - val_loss: 1008828400.0664\n",
      "Epoch 366/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 303422191.2147 - val_loss: 1007520660.7137\n",
      "Epoch 367/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 308206110.5603 - val_loss: 1025214648.2988\n",
      "Epoch 368/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 309563656.4090 - val_loss: 1010191495.9668\n",
      "Epoch 369/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 303398435.7955 - val_loss: 1007273994.0913\n",
      "Epoch 370/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 298238322.4213 - val_loss: 999350097.7925\n",
      "Epoch 371/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 296785013.5297 - val_loss: 998965548.6141\n",
      "Epoch 372/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 296254104.4744 - val_loss: 1003459752.8963\n",
      "Epoch 373/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 297641256.3108 - val_loss: 998632640.7967\n",
      "Epoch 374/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 296599551.8037 - val_loss: 1001231343.5353\n",
      "Epoch 375/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 291611180.1063 - val_loss: 997995459.4523\n",
      "Epoch 376/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 291295099.4847 - val_loss: 996293966.6058\n",
      "Epoch 377/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 293379760.5235 - val_loss: 1001694377.4274\n",
      "Epoch 378/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 298597992.3763 - val_loss: 1007700603.7510\n",
      "Epoch 379/700\n",
      "978/978 [==============================] - 0s 445us/sample - loss: 300225913.4560 - val_loss: 1002959839.0705\n",
      "Epoch 380/700\n",
      "978/978 [==============================] - 0s 433us/sample - loss: 289074960.4254 - val_loss: 994845831.4357\n",
      "Epoch 381/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 287006662.0204 - val_loss: 995318627.8506\n",
      "Epoch 382/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 286130717.7751 - val_loss: 997230561.7261\n",
      "Epoch 383/700\n",
      "978/978 [==============================] - 0s 428us/sample - loss: 291216750.3967 - val_loss: 994210588.6805\n",
      "Epoch 384/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 283121419.2229 - val_loss: 992124913.1286\n",
      "Epoch 385/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 285455324.4335 - val_loss: 995116260.9129\n",
      "Epoch 386/700\n",
      "978/978 [==============================] - 0s 432us/sample - loss: 283022627.6646 - val_loss: 987647618.1245\n",
      "Epoch 387/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 281510484.9407 - val_loss: 988791538.1909\n",
      "Epoch 388/700\n",
      "978/978 [==============================] - 0s 410us/sample - loss: 279373345.4397 - val_loss: 985551029.1120\n",
      "Epoch 389/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 280972222.1677 - val_loss: 986359759.6680\n",
      "Epoch 390/700\n",
      "978/978 [==============================] - 0s 465us/sample - loss: 279239137.1125 - val_loss: 985624693.9087\n",
      "Epoch 391/700\n",
      "978/978 [==============================] - 0s 448us/sample - loss: 278154680.7362 - val_loss: 984745675.4191\n",
      "Epoch 392/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 278714388.5481 - val_loss: 982540462.7386\n",
      "Epoch 393/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 276336295.8200 - val_loss: 982295949.8091\n",
      "Epoch 394/700\n",
      "978/978 [==============================] - 0s 491us/sample - loss: 275246806.7730 - val_loss: 984074772.7137\n",
      "Epoch 395/700\n",
      "978/978 [==============================] - 0s 396us/sample - loss: 273689023.9673 - val_loss: 981206682.5560\n",
      "Epoch 396/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978/978 [==============================] - 0s 441us/sample - loss: 272573249.7342 - val_loss: 981231193.7593\n",
      "Epoch 397/700\n",
      "978/978 [==============================] - 0s 464us/sample - loss: 270919257.2270 - val_loss: 978559646.2739\n",
      "Epoch 398/700\n",
      "978/978 [==============================] - 0s 459us/sample - loss: 270239322.9611 - val_loss: 978679689.5602\n",
      "Epoch 399/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 270354248.7035 - val_loss: 980148706.7884\n",
      "Epoch 400/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 269425356.0736 - val_loss: 975368427.8174\n",
      "Epoch 401/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 270759620.2209 - val_loss: 977439794.9876\n",
      "Epoch 402/700\n",
      "978/978 [==============================] - 0s 402us/sample - loss: 266957170.2577 - val_loss: 978417828.6473\n",
      "Epoch 403/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 267343701.0716 - val_loss: 973954743.7676\n",
      "Epoch 404/700\n",
      "978/978 [==============================] - 0s 471us/sample - loss: 269882979.5337 - val_loss: 976348511.0705\n",
      "Epoch 405/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 267605342.2331 - val_loss: 978517654.3071\n",
      "Epoch 406/700\n",
      "978/978 [==============================] - 0s 454us/sample - loss: 270017463.2638 - val_loss: 972655713.7261\n",
      "Epoch 407/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 261716479.0184 - val_loss: 977391968.6639\n",
      "Epoch 408/700\n",
      "978/978 [==============================] - 0s 437us/sample - loss: 263447133.5133 - val_loss: 971240091.0871\n",
      "Epoch 409/700\n",
      "978/978 [==============================] - 0s 405us/sample - loss: 260813050.1759 - val_loss: 970367441.7925\n",
      "Epoch 410/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 259585520.6871 - val_loss: 972433540.7801\n",
      "Epoch 411/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 260463486.5603 - val_loss: 967724687.4025\n",
      "Epoch 412/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 259637937.9305 - val_loss: 967828926.1411\n",
      "Epoch 413/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 258468533.0061 - val_loss: 969747608.4315\n",
      "Epoch 414/700\n",
      "978/978 [==============================] - 0s 433us/sample - loss: 257749987.1738 - val_loss: 965544295.0373\n",
      "Epoch 415/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 255370252.4990 - val_loss: 964658910.5394\n",
      "Epoch 416/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 256729708.6953 - val_loss: 965199107.1867\n",
      "Epoch 417/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 256725449.8160 - val_loss: 968336626.1909\n",
      "Epoch 418/700\n",
      "978/978 [==============================] - 0s 423us/sample - loss: 254630534.9693 - val_loss: 962770770.3237\n",
      "Epoch 419/700\n",
      "978/978 [==============================] - 0s 406us/sample - loss: 253132169.2270 - val_loss: 969747591.4357\n",
      "Epoch 420/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 256193536.5235 - val_loss: 961793277.8755\n",
      "Epoch 421/700\n",
      "978/978 [==============================] - 0s 385us/sample - loss: 251192399.1166 - val_loss: 968259630.2075\n",
      "Epoch 422/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 249293005.1534 - val_loss: 963781739.8174\n",
      "Epoch 423/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 251333294.2004 - val_loss: 959398403.1867\n",
      "Epoch 424/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 254037655.7546 - val_loss: 961896678.5062\n",
      "Epoch 425/700\n",
      "978/978 [==============================] - 0s 451us/sample - loss: 253278679.9509 - val_loss: 956709833.8257\n",
      "Epoch 426/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 246958496.4581 - val_loss: 959537781.3776\n",
      "Epoch 427/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 250256369.4724 - val_loss: 960975232.0000\n",
      "Epoch 428/700\n",
      "978/978 [==============================] - 0s 429us/sample - loss: 246680636.9243 - val_loss: 961311645.2116\n",
      "Epoch 429/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 245608340.4172 - val_loss: 956113617.7925\n",
      "Epoch 430/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 243321014.7730 - val_loss: 953489320.3651\n",
      "Epoch 431/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 245456638.5603 - val_loss: 954411890.7220\n",
      "Epoch 432/700\n",
      "978/978 [==============================] - 0s 454us/sample - loss: 243019056.0982 - val_loss: 954551712.9295\n",
      "Epoch 433/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 240500858.0123 - val_loss: 952776041.1618\n",
      "Epoch 434/700\n",
      "978/978 [==============================] - 0s 412us/sample - loss: 240638720.3272 - val_loss: 958841521.9253\n",
      "Epoch 435/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 242767781.6933 - val_loss: 953017618.0581\n",
      "Epoch 436/700\n",
      "978/978 [==============================] - 0s 408us/sample - loss: 239646631.8855 - val_loss: 952632427.8174\n",
      "Epoch 437/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 237533662.3640 - val_loss: 951767318.8382\n",
      "Epoch 438/700\n",
      "978/978 [==============================] - 0s 400us/sample - loss: 239999428.5808 - val_loss: 959933256.7635\n",
      "Epoch 439/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 238502481.2434 - val_loss: 950986035.5187\n",
      "Epoch 440/700\n",
      "978/978 [==============================] - 0s 432us/sample - loss: 236237225.0307 - val_loss: 954479776.9295\n",
      "Epoch 441/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 235245790.5603 - val_loss: 950647451.0871\n",
      "Epoch 442/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 236178454.1186 - val_loss: 949740990.6722\n",
      "Epoch 443/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 239297196.7607 - val_loss: 952669769.2946\n",
      "Epoch 444/700\n",
      "978/978 [==============================] - 0s 397us/sample - loss: 236142051.0757 - val_loss: 950389163.0207\n",
      "Epoch 445/700\n",
      "978/978 [==============================] - 0s 408us/sample - loss: 236411326.1022 - val_loss: 945974764.8797\n",
      "Epoch 446/700\n",
      "978/978 [==============================] - 0s 429us/sample - loss: 231545935.4438 - val_loss: 945565365.1120\n",
      "Epoch 447/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 232599298.3558 - val_loss: 945305111.3693\n",
      "Epoch 448/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 231990168.8671 - val_loss: 949436189.7427\n",
      "Epoch 449/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 228215140.7444 - val_loss: 945007192.6971\n",
      "Epoch 450/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 233620723.7955 - val_loss: 948387963.7510\n",
      "Epoch 451/700\n",
      "978/978 [==============================] - 0s 410us/sample - loss: 235840838.0532 - val_loss: 966658470.2407\n",
      "Epoch 452/700\n",
      "978/978 [==============================] - 0s 453us/sample - loss: 238578114.0941 - val_loss: 947414914.1245\n",
      "Epoch 453/700\n",
      "978/978 [==============================] - 0s 404us/sample - loss: 235495916.6953 - val_loss: 942332247.6349\n",
      "Epoch 454/700\n",
      "978/978 [==============================] - 0s 463us/sample - loss: 225477955.5665 - val_loss: 945024285.2116\n",
      "Epoch 455/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 225862207.2147 - val_loss: 942905748.7137\n",
      "Epoch 456/700\n",
      "978/978 [==============================] - 0s 419us/sample - loss: 223066856.3436 - val_loss: 940408532.9793\n",
      "Epoch 457/700\n",
      "978/978 [==============================] - 0s 419us/sample - loss: 223046619.2229 - val_loss: 939669695.2033\n",
      "Epoch 458/700\n",
      "978/978 [==============================] - 0s 398us/sample - loss: 223943043.9918 - val_loss: 944266374.3734\n",
      "Epoch 459/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 221534523.8773 - val_loss: 938759480.8299\n",
      "Epoch 460/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 223471157.1697 - val_loss: 952328779.4191\n",
      "Epoch 461/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 223543786.0123 - val_loss: 950912441.8921\n",
      "Epoch 462/700\n",
      "978/978 [==============================] - 0s 398us/sample - loss: 225376967.9836 - val_loss: 949492477.3444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 221946243.9918 - val_loss: 936688043.5519\n",
      "Epoch 464/700\n",
      "978/978 [==============================] - 0s 433us/sample - loss: 218441792.0654 - val_loss: 937748035.4523\n",
      "Epoch 465/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 218342288.7853 - val_loss: 936634405.7095\n",
      "Epoch 466/700\n",
      "978/978 [==============================] - 0s 456us/sample - loss: 217017074.9121 - val_loss: 935283363.5851\n",
      "Epoch 467/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 217098683.2883 - val_loss: 939280570.9544\n",
      "Epoch 468/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 216007891.1411 - val_loss: 933956327.5685\n",
      "Epoch 469/700\n",
      "978/978 [==============================] - 0s 433us/sample - loss: 213759491.9918 - val_loss: 937395941.9751\n",
      "Epoch 470/700\n",
      "978/978 [==============================] - 0s 398us/sample - loss: 213393318.6094 - val_loss: 936568252.5477\n",
      "Epoch 471/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 212084244.1227 - val_loss: 933087401.4274\n",
      "Epoch 472/700\n",
      "978/978 [==============================] - 0s 445us/sample - loss: 212085926.7403 - val_loss: 935200704.7967\n",
      "Epoch 473/700\n",
      "978/978 [==============================] - 0s 402us/sample - loss: 214344321.7342 - val_loss: 935037076.1826\n",
      "Epoch 474/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 214282786.2249 - val_loss: 954674256.1992\n",
      "Epoch 475/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 225010667.6155 - val_loss: 931363342.3402\n",
      "Epoch 476/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 215882807.7546 - val_loss: 928837245.3444\n",
      "Epoch 477/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 208782087.0675 - val_loss: 932343580.1494\n",
      "Epoch 478/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 207347408.9816 - val_loss: 929434230.4398\n",
      "Epoch 479/700\n",
      "978/978 [==============================] - 0s 428us/sample - loss: 208811622.0204 - val_loss: 930922095.0041\n",
      "Epoch 480/700\n",
      "978/978 [==============================] - 0s 419us/sample - loss: 208780309.9877 - val_loss: 928235621.9751\n",
      "Epoch 481/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 207056521.1616 - val_loss: 926259230.2739\n",
      "Epoch 482/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 208863826.3231 - val_loss: 926637237.1120\n",
      "Epoch 483/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 210029459.2720 - val_loss: 928888561.6598\n",
      "Epoch 484/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 205301697.6033 - val_loss: 932101782.8382\n",
      "Epoch 485/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 201761710.5930 - val_loss: 927745001.6929\n",
      "Epoch 486/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 205640330.0777 - val_loss: 929334727.1701\n",
      "Epoch 487/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 200358419.1411 - val_loss: 929829468.9461\n",
      "Epoch 488/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 203278363.7791 - val_loss: 926874741.3776\n",
      "Epoch 489/700\n",
      "978/978 [==============================] - 0s 459us/sample - loss: 200047022.7566 - val_loss: 923271008.6639\n",
      "Epoch 490/700\n",
      "978/978 [==============================] - 0s 397us/sample - loss: 199850742.7730 - val_loss: 927250829.8091\n",
      "Epoch 491/700\n",
      "978/978 [==============================] - 0s 451us/sample - loss: 201781402.0450 - val_loss: 923428571.8838\n",
      "Epoch 492/700\n",
      "978/978 [==============================] - 0s 438us/sample - loss: 198534409.6196 - val_loss: 923141516.7469\n",
      "Epoch 493/700\n",
      "978/978 [==============================] - 0s 399us/sample - loss: 198106035.1084 - val_loss: 922353889.1950\n",
      "Epoch 494/700\n",
      "978/978 [==============================] - 0s 429us/sample - loss: 198432178.6503 - val_loss: 923376604.4149\n",
      "Epoch 495/700\n",
      "978/978 [==============================] - 0s 423us/sample - loss: 196995036.0736 - val_loss: 924516487.4357\n",
      "Epoch 496/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 196757695.6074 - val_loss: 924099285.5104\n",
      "Epoch 497/700\n",
      "978/978 [==============================] - 0s 419us/sample - loss: 197918076.2045 - val_loss: 922925169.1286\n",
      "Epoch 498/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 195553049.5215 - val_loss: 921144895.7344\n",
      "Epoch 499/700\n",
      "978/978 [==============================] - 0s 485us/sample - loss: 196094622.3967 - val_loss: 919507616.9295\n",
      "Epoch 500/700\n",
      "978/978 [==============================] - 0s 405us/sample - loss: 199351686.4785 - val_loss: 931774835.2531\n",
      "Epoch 501/700\n",
      "978/978 [==============================] - 0s 428us/sample - loss: 196542373.3661 - val_loss: 918769540.2490\n",
      "Epoch 502/700\n",
      "978/978 [==============================] - 0s 447us/sample - loss: 192129511.5583 - val_loss: 918029314.6556\n",
      "Epoch 503/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 191011565.6115 - val_loss: 918610036.3154\n",
      "Epoch 504/700\n",
      "978/978 [==============================] - 0s 465us/sample - loss: 190843409.4070 - val_loss: 919250624.7967\n",
      "Epoch 505/700\n",
      "978/978 [==============================] - 0s 412us/sample - loss: 190070839.1329 - val_loss: 926810362.6888\n",
      "Epoch 506/700\n",
      "978/978 [==============================] - 0s 429us/sample - loss: 191333057.8323 - val_loss: 919792687.2697\n",
      "Epoch 507/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 190735975.8855 - val_loss: 921639066.5560\n",
      "Epoch 508/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 187848972.4990 - val_loss: 918457305.2282\n",
      "Epoch 509/700\n",
      "978/978 [==============================] - 0s 406us/sample - loss: 188820589.2515 - val_loss: 915458961.5270\n",
      "Epoch 510/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 186263342.2331 - val_loss: 915572683.9502\n",
      "Epoch 511/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 186905026.4540 - val_loss: 918860535.5021\n",
      "Epoch 512/700\n",
      "978/978 [==============================] - 0s 383us/sample - loss: 187892033.2434 - val_loss: 915898276.6473\n",
      "Epoch 513/700\n",
      "978/978 [==============================] - 0s 415us/sample - loss: 188068424.6708 - val_loss: 918409856.5311\n",
      "Epoch 514/700\n",
      "978/978 [==============================] - 0s 447us/sample - loss: 186041176.9980 - val_loss: 915642513.5270\n",
      "Epoch 515/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 184957663.2147 - val_loss: 914621138.8548\n",
      "Epoch 516/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 183502322.1595 - val_loss: 913022372.1162\n",
      "Epoch 517/700\n",
      "978/978 [==============================] - 0s 448us/sample - loss: 185143929.2924 - val_loss: 912948408.8299\n",
      "Epoch 518/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 182575214.8875 - val_loss: 915821657.7593\n",
      "Epoch 519/700\n",
      "978/978 [==============================] - 0s 438us/sample - loss: 184556752.8834 - val_loss: 910374174.8050\n",
      "Epoch 520/700\n",
      "978/978 [==============================] - 0s 410us/sample - loss: 181206001.9632 - val_loss: 910037285.1784\n",
      "Epoch 521/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 181256194.0777 - val_loss: 910442791.8340\n",
      "Epoch 522/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 180802188.2699 - val_loss: 910510269.0788\n",
      "Epoch 523/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 179735469.0061 - val_loss: 909571521.8589\n",
      "Epoch 524/700\n",
      "978/978 [==============================] - 0s 404us/sample - loss: 180603306.6339 - val_loss: 909151104.5311\n",
      "Epoch 525/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 179576110.1350 - val_loss: 909312860.9461\n",
      "Epoch 526/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 177723599.9673 - val_loss: 909595653.8423\n",
      "Epoch 527/700\n",
      "978/978 [==============================] - 0s 394us/sample - loss: 177492330.7975 - val_loss: 912139591.1701\n",
      "Epoch 528/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 179964457.2597 - val_loss: 921095913.6929\n",
      "Epoch 529/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978/978 [==============================] - 0s 428us/sample - loss: 179111067.1902 - val_loss: 906438298.0249\n",
      "Epoch 530/700\n",
      "978/978 [==============================] - 0s 412us/sample - loss: 177275825.7014 - val_loss: 907078701.1452\n",
      "Epoch 531/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 179249095.7710 - val_loss: 926281895.3029\n",
      "Epoch 532/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 183321468.4663 - val_loss: 909163911.4357\n",
      "Epoch 533/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 181085978.0450 - val_loss: 911815618.3900\n",
      "Epoch 534/700\n",
      "978/978 [==============================] - 0s 470us/sample - loss: 175588424.8671 - val_loss: 916297861.3112\n",
      "Epoch 535/700\n",
      "978/978 [==============================] - 0s 450us/sample - loss: 175970540.4663 - val_loss: 904818349.1452\n",
      "Epoch 536/700\n",
      "978/978 [==============================] - 0s 403us/sample - loss: 176472100.0573 - val_loss: 908908001.7261\n",
      "Epoch 537/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 174448781.0225 - val_loss: 908116031.7344\n",
      "Epoch 538/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 175678393.1288 - val_loss: 906087317.7759\n",
      "Epoch 539/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 173731382.8712 - val_loss: 902164306.8548\n",
      "Epoch 540/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 170090348.5971 - val_loss: 903587283.9170\n",
      "Epoch 541/700\n",
      "978/978 [==============================] - 0s 433us/sample - loss: 169581309.6769 - val_loss: 903126262.4398\n",
      "Epoch 542/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 170779908.9734 - val_loss: 902603268.7801\n",
      "Epoch 543/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 169315330.7812 - val_loss: 901562966.0415\n",
      "Epoch 544/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 168629997.4151 - val_loss: 900732733.0788\n",
      "Epoch 545/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 169165155.4356 - val_loss: 905052148.3154\n",
      "Epoch 546/700\n",
      "978/978 [==============================] - 0s 400us/sample - loss: 167433846.8384 - val_loss: 916022892.3485\n",
      "Epoch 547/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 173803843.8282 - val_loss: 908049133.4108\n",
      "Epoch 548/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 177896633.1943 - val_loss: 899449780.0498\n",
      "Epoch 549/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 171903037.7423 - val_loss: 919527763.3859\n",
      "Epoch 550/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 173453044.3845 - val_loss: 900725599.6017\n",
      "Epoch 551/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 178278485.8241 - val_loss: 911004302.8714\n",
      "Epoch 552/700\n",
      "978/978 [==============================] - 0s 455us/sample - loss: 174478572.8916 - val_loss: 915575928.5643\n",
      "Epoch 553/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 169657229.3824 - val_loss: 898237988.6473\n",
      "Epoch 554/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 164759433.4233 - val_loss: 901946805.1120\n",
      "Epoch 555/700\n",
      "978/978 [==============================] - 0s 470us/sample - loss: 175189280.3599 - val_loss: 917154225.9253\n",
      "Epoch 556/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 177983329.6196 - val_loss: 901099726.0747\n",
      "Epoch 557/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 173220322.9121 - val_loss: 904750817.1950\n",
      "Epoch 558/700\n",
      "978/978 [==============================] - 0s 393us/sample - loss: 163107000.9325 - val_loss: 903807359.4689\n",
      "Epoch 559/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 163149207.0675 - val_loss: 894102141.8755\n",
      "Epoch 560/700\n",
      "978/978 [==============================] - 0s 443us/sample - loss: 165553088.9816 - val_loss: 894842484.8465\n",
      "Epoch 561/700\n",
      "978/978 [==============================] - 0s 429us/sample - loss: 158854874.3395 - val_loss: 894866690.1245\n",
      "Epoch 562/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 159454776.9980 - val_loss: 899780941.0124\n",
      "Epoch 563/700\n",
      "978/978 [==============================] - 0s 447us/sample - loss: 161472925.5133 - val_loss: 904943506.0581\n",
      "Epoch 564/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 163845964.7280 - val_loss: 902298487.5021\n",
      "Epoch 565/700\n",
      "978/978 [==============================] - 0s 432us/sample - loss: 162355055.4601 - val_loss: 894896077.0124\n",
      "Epoch 566/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 155810070.2168 - val_loss: 892972534.9710\n",
      "Epoch 567/700\n",
      "978/978 [==============================] - 0s 447us/sample - loss: 156294395.7791 - val_loss: 892832357.4440\n",
      "Epoch 568/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 154304245.1534 - val_loss: 893658859.8174\n",
      "Epoch 569/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 154575772.7935 - val_loss: 892709371.2199\n",
      "Epoch 570/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 153993128.0164 - val_loss: 892780526.4730\n",
      "Epoch 571/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 155402023.5910 - val_loss: 891684522.4896\n",
      "Epoch 572/700\n",
      "978/978 [==============================] - 0s 382us/sample - loss: 153097301.6278 - val_loss: 891441735.1701\n",
      "Epoch 573/700\n",
      "978/978 [==============================] - 0s 446us/sample - loss: 156452730.5358 - val_loss: 893090170.1577\n",
      "Epoch 574/700\n",
      "978/978 [==============================] - 0s 438us/sample - loss: 152442211.2229 - val_loss: 895783973.7095\n",
      "Epoch 575/700\n",
      "978/978 [==============================] - 0s 437us/sample - loss: 151654447.9673 - val_loss: 894387612.6805\n",
      "Epoch 576/700\n",
      "978/978 [==============================] - 0s 443us/sample - loss: 154119138.6830 - val_loss: 899406716.8133\n",
      "Epoch 577/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 162776879.3620 - val_loss: 897182069.3776\n",
      "Epoch 578/700\n",
      "978/978 [==============================] - 0s 406us/sample - loss: 154530302.4867 - val_loss: 891493372.2822\n",
      "Epoch 579/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 151291822.3640 - val_loss: 888240417.4606\n",
      "Epoch 580/700\n",
      "978/978 [==============================] - 0s 449us/sample - loss: 149081469.9059 - val_loss: 891053120.7967\n",
      "Epoch 581/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 149113287.3292 - val_loss: 891491807.0705\n",
      "Epoch 582/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 151377465.8487 - val_loss: 889942160.4647\n",
      "Epoch 583/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 150430649.6851 - val_loss: 888347014.9046\n",
      "Epoch 584/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 147543424.5235 - val_loss: 889507245.6763\n",
      "Epoch 585/700\n",
      "978/978 [==============================] - 0s 416us/sample - loss: 146916943.4110 - val_loss: 890826118.9046\n",
      "Epoch 586/700\n",
      "978/978 [==============================] - 0s 435us/sample - loss: 151398876.8098 - val_loss: 889448071.9668\n",
      "Epoch 587/700\n",
      "978/978 [==============================] - 0s 406us/sample - loss: 147507145.6524 - val_loss: 890703364.2490\n",
      "Epoch 588/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 144735310.5930 - val_loss: 887210176.2656\n",
      "Epoch 589/700\n",
      "978/978 [==============================] - 0s 465us/sample - loss: 145157897.8487 - val_loss: 886898102.1743\n",
      "Epoch 590/700\n",
      "978/978 [==============================] - 0s 437us/sample - loss: 144045251.9918 - val_loss: 890204355.9834\n",
      "Epoch 591/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 147568256.6871 - val_loss: 890669885.6100\n",
      "Epoch 592/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 145079300.3681 - val_loss: 886651001.6266\n",
      "Epoch 593/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 143745108.0245 - val_loss: 890841754.0249\n",
      "Epoch 594/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 145928256.8016 - val_loss: 888712609.9917\n",
      "Epoch 595/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 141524741.6933 - val_loss: 887857037.2780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 596/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 140698990.6912 - val_loss: 888660602.6888\n",
      "Epoch 597/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 141179396.0573 - val_loss: 891542559.8672\n",
      "Epoch 598/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 143810070.8548 - val_loss: 887350583.7676\n",
      "Epoch 599/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 141126588.4008 - val_loss: 887552271.4025\n",
      "Epoch 600/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 140056650.5685 - val_loss: 887452002.2573\n",
      "Epoch 601/700\n",
      "978/978 [==============================] - 0s 392us/sample - loss: 139330927.8364 - val_loss: 887270171.6183\n",
      "Epoch 602/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 140847421.2843 - val_loss: 887153514.2241\n",
      "Epoch 603/700\n",
      "978/978 [==============================] - 0s 428us/sample - loss: 140347618.0613 - val_loss: 897163387.2199\n",
      "Epoch 604/700\n",
      "978/978 [==============================] - 0s 448us/sample - loss: 138721904.9489 - val_loss: 888987006.4066\n",
      "Epoch 605/700\n",
      "978/978 [==============================] - 0s 404us/sample - loss: 138963783.1984 - val_loss: 884167405.9419\n",
      "Epoch 606/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 136827081.0798 - val_loss: 885325832.4979\n",
      "Epoch 607/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 136727375.6074 - val_loss: 886033069.6763\n",
      "Epoch 608/700\n",
      "978/978 [==============================] - 0s 436us/sample - loss: 135843831.0675 - val_loss: 884810723.3195\n",
      "Epoch 609/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 135728877.4151 - val_loss: 883471601.6598\n",
      "Epoch 610/700\n",
      "978/978 [==============================] - 0s 410us/sample - loss: 134940053.1697 - val_loss: 884354194.0581\n",
      "Epoch 611/700\n",
      "978/978 [==============================] - 0s 396us/sample - loss: 133892929.1452 - val_loss: 882142108.6805\n",
      "Epoch 612/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 133269530.4049 - val_loss: 883630285.5436\n",
      "Epoch 613/700\n",
      "978/978 [==============================] - 0s 447us/sample - loss: 133030060.5481 - val_loss: 884549958.1079\n",
      "Epoch 614/700\n",
      "978/978 [==============================] - 0s 443us/sample - loss: 133786514.9448 - val_loss: 890525115.4855\n",
      "Epoch 615/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 136291622.9857 - val_loss: 885520849.2614\n",
      "Epoch 616/700\n",
      "978/978 [==============================] - 0s 459us/sample - loss: 135524443.8937 - val_loss: 884587517.8755\n",
      "Epoch 617/700\n",
      "978/978 [==============================] - 0s 408us/sample - loss: 132636671.8691 - val_loss: 883091929.7593\n",
      "Epoch 618/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 132747179.4029 - val_loss: 887695154.9876\n",
      "Epoch 619/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 131193466.3231 - val_loss: 883437070.8714\n",
      "Epoch 620/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 132118421.3661 - val_loss: 882070296.9627\n",
      "Epoch 621/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 132103166.9202 - val_loss: 889677259.4191\n",
      "Epoch 622/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 132663503.8037 - val_loss: 883771749.9751\n",
      "Epoch 623/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 134448586.9284 - val_loss: 883388815.4025\n",
      "Epoch 624/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 127957812.7117 - val_loss: 885329061.7095\n",
      "Epoch 625/700\n",
      "978/978 [==============================] - 0s 453us/sample - loss: 127647992.4254 - val_loss: 884957936.5975\n",
      "Epoch 626/700\n",
      "978/978 [==============================] - 0s 449us/sample - loss: 127250899.4029 - val_loss: 883139491.5851\n",
      "Epoch 627/700\n",
      "978/978 [==============================] - 0s 389us/sample - loss: 126709202.0941 - val_loss: 884052588.8797\n",
      "Epoch 628/700\n",
      "978/978 [==============================] - 0s 449us/sample - loss: 127369983.1329 - val_loss: 884575753.0290\n",
      "Epoch 629/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 127597615.5092 - val_loss: 887726558.0083\n",
      "Epoch 630/700\n",
      "978/978 [==============================] - 0s 456us/sample - loss: 126981333.7914 - val_loss: 882090414.7386\n",
      "Epoch 631/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 125340216.0818 - val_loss: 882687565.5436\n",
      "Epoch 632/700\n",
      "978/978 [==============================] - 0s 404us/sample - loss: 124562375.8773 - val_loss: 883687815.4357\n",
      "Epoch 633/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 124289158.1840 - val_loss: 883127943.9668\n",
      "Epoch 634/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 129504227.4356 - val_loss: 891141301.1120\n",
      "Epoch 635/700\n",
      "978/978 [==============================] - 0s 370us/sample - loss: 135692323.3047 - val_loss: 896922977.1950\n",
      "Epoch 636/700\n",
      "978/978 [==============================] - 0s 409us/sample - loss: 129318870.4294 - val_loss: 886567611.4855\n",
      "Epoch 637/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 129687405.5951 - val_loss: 885471882.6224\n",
      "Epoch 638/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 124040627.5992 - val_loss: 884726999.6349\n",
      "Epoch 639/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 123554364.6626 - val_loss: 882764647.0373\n",
      "Epoch 640/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 128492485.5297 - val_loss: 883050876.8133\n",
      "Epoch 641/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 121835220.4663 - val_loss: 881490709.7759\n",
      "Epoch 642/700\n",
      "978/978 [==============================] - 0s 434us/sample - loss: 121477958.7076 - val_loss: 884382184.0996\n",
      "Epoch 643/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 119811976.6871 - val_loss: 880664296.6307\n",
      "Epoch 644/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 122397021.4642 - val_loss: 880857239.9004\n",
      "Epoch 645/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 122092094.7566 - val_loss: 885300961.1950\n",
      "Epoch 646/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 120479085.1043 - val_loss: 881526255.5353\n",
      "Epoch 647/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 119962197.7423 - val_loss: 881684472.5643\n",
      "Epoch 648/700\n",
      "978/978 [==============================] - 0s 419us/sample - loss: 120777613.4151 - val_loss: 884743432.4979\n",
      "Epoch 649/700\n",
      "978/978 [==============================] - 0s 405us/sample - loss: 122480306.3231 - val_loss: 881276615.7012\n",
      "Epoch 650/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 119446590.9039 - val_loss: 885198245.1784\n",
      "Epoch 651/700\n",
      "978/978 [==============================] - 0s 437us/sample - loss: 116534815.4192 - val_loss: 888066034.1909\n",
      "Epoch 652/700\n",
      "978/978 [==============================] - 0s 401us/sample - loss: 124375668.0573 - val_loss: 882584321.0622\n",
      "Epoch 653/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 118698554.9121 - val_loss: 891160353.9917\n",
      "Epoch 654/700\n",
      "978/978 [==============================] - 0s 406us/sample - loss: 119900037.6933 - val_loss: 890428420.7801\n",
      "Epoch 655/700\n",
      "978/978 [==============================] - 0s 419us/sample - loss: 117805201.7832 - val_loss: 880268234.8880\n",
      "Epoch 656/700\n",
      "978/978 [==============================] - 0s 444us/sample - loss: 115180392.9816 - val_loss: 881955209.0290\n",
      "Epoch 657/700\n",
      "978/978 [==============================] - 0s 406us/sample - loss: 115254580.3845 - val_loss: 884346735.0041\n",
      "Epoch 658/700\n",
      "978/978 [==============================] - 0s 433us/sample - loss: 114477577.1125 - val_loss: 880597470.5394\n",
      "Epoch 659/700\n",
      "978/978 [==============================] - 0s 422us/sample - loss: 116367200.4090 - val_loss: 880461992.3651\n",
      "Epoch 660/700\n",
      "978/978 [==============================] - 0s 413us/sample - loss: 114516615.4928 - val_loss: 881707446.1743\n",
      "Epoch 661/700\n",
      "978/978 [==============================] - 0s 447us/sample - loss: 114343199.0348 - val_loss: 884021841.2614\n",
      "Epoch 662/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978/978 [==============================] - 0s 432us/sample - loss: 112805881.6033 - val_loss: 881765908.7137\n",
      "Epoch 663/700\n",
      "978/978 [==============================] - 0s 388us/sample - loss: 112579809.3906 - val_loss: 881768207.9336\n",
      "Epoch 664/700\n",
      "978/978 [==============================] - 0s 453us/sample - loss: 112259714.6176 - val_loss: 883161955.8506\n",
      "Epoch 665/700\n",
      "978/978 [==============================] - 0s 411us/sample - loss: 112042210.9121 - val_loss: 884777040.1992\n",
      "Epoch 666/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 115113781.3333 - val_loss: 883064364.6141\n",
      "Epoch 667/700\n",
      "978/978 [==============================] - 0s 453us/sample - loss: 112133331.6973 - val_loss: 884506021.1784\n",
      "Epoch 668/700\n",
      "978/978 [==============================] - 0s 414us/sample - loss: 111560386.7975 - val_loss: 887574992.1992\n",
      "Epoch 669/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 111442058.4049 - val_loss: 881255889.2614\n",
      "Epoch 670/700\n",
      "978/978 [==============================] - 1s 522us/sample - loss: 110481488.8834 - val_loss: 882765954.1245\n",
      "Epoch 671/700\n",
      "978/978 [==============================] - 0s 437us/sample - loss: 109405195.0593 - val_loss: 890207622.9046\n",
      "Epoch 672/700\n",
      "978/978 [==============================] - 0s 449us/sample - loss: 114896809.4560 - val_loss: 880819661.5436\n",
      "Epoch 673/700\n",
      "978/978 [==============================] - 0s 425us/sample - loss: 110666380.4335 - val_loss: 891510499.3195\n",
      "Epoch 674/700\n",
      "978/978 [==============================] - 0s 430us/sample - loss: 115156748.5235 - val_loss: 888458027.5519\n",
      "Epoch 675/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 109718632.3763 - val_loss: 880718021.5768\n",
      "Epoch 676/700\n",
      "978/978 [==============================] - 0s 426us/sample - loss: 108674208.0164 - val_loss: 881629162.7552\n",
      "Epoch 677/700\n",
      "978/978 [==============================] - 0s 401us/sample - loss: 112132900.4172 - val_loss: 884862490.0249\n",
      "Epoch 678/700\n",
      "978/978 [==============================] - 0s 459us/sample - loss: 109829263.3783 - val_loss: 889811107.0539\n",
      "Epoch 679/700\n",
      "978/978 [==============================] - 0s 458us/sample - loss: 114020463.7055 - val_loss: 892893816.5643\n",
      "Epoch 680/700\n",
      "978/978 [==============================] - 0s 421us/sample - loss: 109240071.1166 - val_loss: 883904974.6058\n",
      "Epoch 681/700\n",
      "978/978 [==============================] - 0s 418us/sample - loss: 106657757.6605 - val_loss: 884377206.4398\n",
      "Epoch 682/700\n",
      "978/978 [==============================] - 0s 446us/sample - loss: 107630704.1063 - val_loss: 883970806.4398\n",
      "Epoch 683/700\n",
      "978/978 [==============================] - 0s 439us/sample - loss: 106288081.0798 - val_loss: 882861062.3734\n",
      "Epoch 684/700\n",
      "978/978 [==============================] - 0s 441us/sample - loss: 106876848.7198 - val_loss: 884020032.2656\n",
      "Epoch 685/700\n",
      "978/978 [==============================] - 0s 407us/sample - loss: 105382308.8098 - val_loss: 885687424.0000\n",
      "Epoch 686/700\n",
      "978/978 [==============================] - 0s 438us/sample - loss: 103741619.1575 - val_loss: 885742383.8008\n",
      "Epoch 687/700\n",
      "978/978 [==============================] - 0s 397us/sample - loss: 104593895.5910 - val_loss: 886464990.0083\n",
      "Epoch 688/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 103965421.3170 - val_loss: 881757295.0041\n",
      "Epoch 689/700\n",
      "978/978 [==============================] - 0s 450us/sample - loss: 102984845.4806 - val_loss: 884939650.6556\n",
      "Epoch 690/700\n",
      "978/978 [==============================] - 0s 440us/sample - loss: 106030090.3067 - val_loss: 890573240.2988\n",
      "Epoch 691/700\n",
      "978/978 [==============================] - 0s 448us/sample - loss: 106999254.2822 - val_loss: 893014876.4149\n",
      "Epoch 692/700\n",
      "978/978 [==============================] - 0s 427us/sample - loss: 103989452.4663 - val_loss: 884839504.7303\n",
      "Epoch 693/700\n",
      "978/978 [==============================] - 0s 401us/sample - loss: 103117264.8671 - val_loss: 884421581.0124\n",
      "Epoch 694/700\n",
      "978/978 [==============================] - 0s 449us/sample - loss: 103863526.7403 - val_loss: 888800838.1079\n",
      "Epoch 695/700\n",
      "978/978 [==============================] - 0s 431us/sample - loss: 105187442.7485 - val_loss: 881624179.2531\n",
      "Epoch 696/700\n",
      "978/978 [==============================] - 0s 420us/sample - loss: 106176447.1656 - val_loss: 884141125.0456\n",
      "Epoch 697/700\n",
      "978/978 [==============================] - 0s 442us/sample - loss: 101541455.6401 - val_loss: 883008530.0581\n",
      "Epoch 698/700\n",
      "978/978 [==============================] - 0s 417us/sample - loss: 100419461.8978 - val_loss: 882300094.1411\n",
      "Epoch 699/700\n",
      "978/978 [==============================] - 0s 424us/sample - loss: 99886597.4642 - val_loss: 883383023.5353\n",
      "Epoch 700/700\n",
      "978/978 [==============================] - 0s 401us/sample - loss: 100330183.7382 - val_loss: 883576428.3485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x81d74f90>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y =y_train, epochs = 700, batch_size=128, validation_data=(X_test, y_test))#, callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x758501b0>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1460.000000\n",
       "mean     180921.195890\n",
       "std       79442.502883\n",
       "min       34900.000000\n",
       "25%      129975.000000\n",
       "50%      163000.000000\n",
       "75%      214000.000000\n",
       "max      755000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29725.012959285337"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, predictions) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130998.64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = src_df[src_df['source'] == 'test'].drop(['source','SalePrice'], axis = 1 )\n",
    "sample = df_predict.iloc[0][1:].values.reshape(-1, 288)\n",
    "model.predict(scaler.transform(sample))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = src_df[src_df['source'] == 'test']\n",
    "df_predict = df_predict.drop(['source','SalePrice'], axis = 1)\n",
    "df_predict = df_predict.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n",
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n"
     ]
    }
   ],
   "source": [
    "suffix = time.strftime('%Y%m%d_%H%M')\n",
    "filename =  'kaggle_house_prediction_' + suffix + '.csv'\n",
    "f = open(filename, 'w+')\n",
    "f.write('Id,SalePrice\\r\\n')\n",
    "for i in range(len(df_predict)): #range(100):\n",
    "    curr = df_predict.iloc[i][1:].values.reshape(-1, 288)\n",
    "    predict = model.predict(scaler.transform(curr))\n",
    "    if i%50 == 0: print(i)\n",
    "    f.write(str(int(df_predict.iloc[i][0]))+','+str(predict[0][0]) + '\\r\\n')\n",
    "\n",
    "f.close()    \n",
    "    \n",
    "#     curr = d.drop('Id', axis=1)\n",
    "#     curr = scaler.transform(d.drop('Id', axis=1).values.reshape(-1, 19))\n",
    "#     predict = model.predict(curr)\n",
    "#     print(d['Id'], predict[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(978, 288)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kaggle_house_price_prediction_20200607.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_288 (Dense)            multiple                  83232     \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            multiple                  83232     \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            multiple                  73984     \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            multiple                  257       \n",
      "=================================================================\n",
      "Total params: 240,705\n",
      "Trainable params: 240,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
